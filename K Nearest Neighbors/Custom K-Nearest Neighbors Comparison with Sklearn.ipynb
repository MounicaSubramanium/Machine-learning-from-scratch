{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing K-Nearest Neighbors (Implemented from Scratch) - \n",
    "\n",
    "We are done with the implementation of KNN from scratch. Now, we just need to test it on a real world dataset to see how it does with a classification task. Next, I will also train the dataset with sklearn implementation of KNN and compare the results of both to see if we are any closer to it. \n",
    "\n",
    "\n",
    "### Dataset - \n",
    "\n",
    "I will use the famous Iris dataset for the Classification. It has 3 class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.chdir('N:\\Machine Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the K-Nearest Neighbors and Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneighbors import KNearestNeighbors\n",
    "from ml_utils import minkowski, train_test_split, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, Y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x247ebd7b2e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_seed=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNearestNeighbors(k=5, p_metric=2)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning \n",
    "\n",
    "I have implemented the distance metric 'minkowski' so as to include both Euclidean and Manhattan distances. \n",
    "After trying a couple of values, I am using K=10 and p=1 for Manhattan distance as it performs better in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNearestNeighbors(k=20, p_metric=1)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after just a bit of tuning, ***Custom implemented model of K-Nearest Neighbors is able to achieve 96.6% accuracy on test set which is great. ***\n",
    "\n",
    "\n",
    "### Sklearn Implementation \n",
    "\n",
    "Now I will run the sklearn implementation of KNN and give the same hyperparameters and see what accuracy we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=20, p=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Great! so we get exactly similar result which means that we did not make any mistake in implementing KNN from scratch logically. ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We can further do a lot of things with this, feature scaling will improve the accuracy further as KNN is a distance based algorithm. We can use Ball Tree or KD Tree algorithm instead of Brute force for finding the Nearest Data points, etc. But my main aim in this was to implement KNN from scratch using only built in python libraries and understand its underlining Mathematics***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
